{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнение тестового задания для g-plans.com\n",
    "#### ovesgur@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Задание(кратко):</b> <br>\n",
    "    Из входных csv файлов мониторинга источника трафика необходимо подготовить набор для создания отчетов. <br>\n",
    "    Файлы - ad_sys.csv, billing_sys.csv, internal_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Table of contents</b> </br>\n",
    "1. [Импорт](#import)\n",
    "2. [Создание класса подготовки таблицы](#creation_class)\n",
    "3. [Создание объекта класса](#creation_obj)\n",
    "4. [Размышления и результаты](#results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание класса подготовки таблицы\n",
    "<a id=\"creation_class\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class view_creator:\n",
    "    def __init__(self, files, sql_server_nm, db_nm, db_tables_nm):\n",
    "        conn = self.connect_db(sql_server_nm, db_nm)\n",
    "        self.create_tables(conn, db_tables_nm)\n",
    "        self.insert_data_bulk(conn, files, db_tables_nm)\n",
    "        self.union_tables(conn, db_tables_nm)\n",
    "        self.drop_nulls(conn, db_tables_nm)\n",
    "        conn.close\n",
    "        \n",
    "    def connect_db(self, sql_server_nm, db_nm):\n",
    "        conn = pyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};server=\" + sql_server_nm + \"; database=revenue_spent_db; trusted_connection=yes;\",autocommit=True)\n",
    "        return conn\n",
    "    \n",
    "    def create_tables(self, conn, db_tables_nm):\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE ''' + db_tables_nm[0] + ''' (\n",
    "        date DATE,\n",
    "        revenue REAL,\n",
    "        spent REAL,\n",
    "        _collected_at VARCHAR(100),\n",
    "        affid INT); ''')\n",
    "        cursor.close\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE ''' + db_tables_nm[1] + ''' (\n",
    "        created_at VARCHAR(100),\n",
    "        affid REAL,\n",
    "        amount REAL,\n",
    "        uid VARCHAR(100)\n",
    "        ); ''' )\n",
    "        cursor.close\n",
    "                \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE ''' + db_tables_nm[2] + ''' (\n",
    "        created_at VARCHAR(100),\n",
    "        affid REAL,\n",
    "        revenue REAL,\n",
    "        user_id VARCHAR(100)\n",
    "        ); ''' )\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        CREATE TABLE ''' + db_tables_nm[3] + ''' (\n",
    "        system VARCHAR(1000),\n",
    "        affid REAL,\n",
    "        revenue REAL,\n",
    "        spent REAL,\n",
    "        date DATETIME\n",
    "        ); ''' )\n",
    "        cursor.close\n",
    "                    \n",
    "        conn.commit()\n",
    "        \n",
    "    \n",
    "    def insert_data_bulk(self, conn, files, db_tables_nm):\n",
    "        qry = \"BULK INSERT \" + db_tables_nm[0] + \" FROM '\" + files[0] + \"' WITH (FIRSTROW = 2, FIELDTERMINATOR =',', ROWTERMINATOR = '0x0a')\"\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        success = cursor.execute(qry)\n",
    "                       \n",
    "        conn.commit()\n",
    "        cursor.close\n",
    "                       \n",
    "        qry = \"BULK INSERT \" + db_tables_nm[1] + \" FROM '\" + files[1] + \"' WITH (FIRSTROW = 2, FIELDTERMINATOR =',', ROWTERMINATOR = '0x0a')\"\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        success = cursor.execute(qry)\n",
    "                       \n",
    "        conn.commit()\n",
    "        cursor.close\n",
    "                       \n",
    "        qry = \"BULK INSERT \" + db_tables_nm[2] + \" FROM '\" + files[2] + \"' WITH (FIRSTROW = 2, FIELDTERMINATOR =',', ROWTERMINATOR = '0x0a')\"\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        success = cursor.execute(qry)\n",
    "                       \n",
    "        conn.commit()\n",
    "        cursor.close\n",
    "    \n",
    "    def union_tables(self, conn, db_tables_nm):\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        INSERT INTO ''' + db_tables_nm[3] + ''' \n",
    "        SELECT 1 AS id_system, affid, revenue, spent, CONVERT(DATETIME, REPLACE(LEFT(adv._collected_at, CHARINDEX('.',adv._collected_at)-1),'_',' '), 102 ) date\n",
    "        FROM dbo.ad_sys adv\n",
    "        ''')\n",
    "        cursor.close\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        INSERT INTO ''' + db_tables_nm[3] + ''' \n",
    "        SELECT 2 AS id_system, affid, amount as revenue, 0 as spent, CONVERT(DATETIME, REPLACE(LEFT(bil_sys.created_at, CHARINDEX('U',bil_sys.created_at)-1),'_',' '), 102 )\n",
    "        FROM dbo.billing_sys bil_sys\n",
    "        ''')\n",
    "        cursor.close\n",
    "        \n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "        INSERT INTO ''' + db_tables_nm[3] + ''' \n",
    "        SELECT 3 AS id_system, affid, revenue, 0 as spent, CONVERT(DATETIME, REPLACE(LEFT(ie_sys.created_at, CHARINDEX('.',ie_sys.created_at)-1),'_',' '), 102 ) date\n",
    "        FROM dbo.internal_events_sys ie_sys\n",
    "        ''')\n",
    "        cursor.close\n",
    "        \n",
    "    def drop_nulls(self, conn, db_tables_nm):\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "         DELETE FROM ''' + db_tables_nm[3] + ''' \n",
    "         where affid is NULL or system is NULL or revenue is NULL or spent is NULL or date is NULL\n",
    "        ''')\n",
    "        cursor.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание объекта класса\n",
    "<a id=\"creation_obj\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\"ad_sys\", \"billing_sys\", \"internal_events_sys\", \"revenue_spent_rep_table\"]\n",
    "files = [r'C:\\\\csvs_for_test_task\\\\ad_sys.csv', r'C:\\\\csvs_for_test_task\\\\billing_sys.csv', r'C:\\\\csvs_for_test_task\\\\internal_events.csv'] \n",
    "creator = view_creator(files, '.', 'revenue_spent_db', tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Размышления и результаты\n",
    "<a id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь, увидев \"Построить витрину\" на ум пришло классическое понимание data mart'а для BI-аналитики, которую я и начал строить в SQL Server Integration Services, затем я планировал собрать табличную модель и даже сделать эти самые отчеты в Power Bi или Tableau, но затем понял, что данных недостаточно, да и задача этого не требует.\n",
    "<br>\n",
    "<img src=\"mart.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Для фильтрации и аналитики необходимо: </b>\n",
    "<br>\n",
    "1. Выбирать конкретную систему, откуда смотреть значения (1,2,3 в столбце system)\n",
    "<br>\n",
    "2. Иметь возможность просмотра за различную дату и возможность интепретировать ее в разные часовые пояса (date в формате datetime) | Вычисляемыми столбцами или средствами BI-инструмента\n",
    "<br>\n",
    "3. Получать данные по тратам на рекламу (select spent from revenue_spent_rep_table where system = 1 (Рекламная система) )\n",
    "4. Получать данные по источнику - affid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tables.png\" alt=\"draw\" style=\"width: 800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Через pyodbc создав таблицы, импортировав их bulk insert из файлов. Итоговая таблица выглядит следующим образом:</b>\n",
    "<img src=\"table_view.png\">\n",
    "\n",
    "Дата была обрезана до момента UTC или точки и переведена в формат datetime, строки с пустыми значениями были удалены (не знаю, подразумевалось ли это заданием)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Под \"создать view или представление\" вряд ли подразумевалась таблица, скорее всего именно sql`ное view. Хотелось бы услышать фидбек, насколько проделанная работа соответствует ожидаемому результату и отвечает ли вообще поставленным требованиям. Заранее благодарю </b> "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
